{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pandas.io.json import json_normalize\n",
    "import json\n",
    "from PyPDF2 import PdfFileWriter, PdfFileReader\n",
    "import time\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Endpoints and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# API details\n",
    "APIEndpoint = \"\" #Your endpoint here \"https://[YourEndpoint].cognitiveservices.azure.com/formrecognizer/documentModels/\"\n",
    "APIKey = \"\" # APIKEY\n",
    "Model = \"\"   #Your trained model\n",
    "\n",
    "# the target PDF document to split\n",
    "filename = r''\n",
    "\n",
    "# the Excel file to export inferences\n",
    "OutputExcel = r''\n",
    "\n",
    "print(filename)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splif PDF File\n",
    "\n",
    "Create multi files for every page on the original document.  Add all files to a python list.  Will later be used to iterate it thru form recognizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileList = list()\n",
    "\n",
    "inputpdf = PdfFileReader(open(filename, \"rb\"))\n",
    "\n",
    "for i in range(inputpdf.numPages):\n",
    "    output = PdfFileWriter()\n",
    "    output.addPage(inputpdf.getPage(i))\n",
    "    with open(\"document-page%s.pdf\" % i, \"wb\") as outputStream:\n",
    "        output.write(outputStream)\n",
    "        fileList.append(r'' % i) #Destination Directory for your split files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fileList)\n",
    "len(fileList)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Request Analysis\n",
    "\n",
    "Analysis is done async, we need two API calls, \n",
    "1. To request the analysis\n",
    "2. To request the results of the analysis\n",
    "\n",
    "- Setup the cognitive service and send PDF file for analysis\n",
    "- Get the request Id sent back by the service located in the headers (APIM Request Id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Inference(FileName):\n",
    "    url = APIEndpoint + Model + \":analyze?api-version=2022-08-31\"\n",
    "    payload =  {'file': open(r'%s' %FileName, 'rb')}\n",
    "    headers = {\n",
    "    'Ocp-Apim-Subscription-Key': APIKey,\n",
    "    'Content-Type': 'application/pdf'\n",
    "    }\n",
    "    \n",
    "    response = requests.request(\"POST\", url, headers=headers, files=payload)\n",
    "    print (response.text)\n",
    "    return response.headers.get('apim-request-id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def GetInference(request_id):\n",
    "  # if response.status_code == 200 or response.status_code == 202:\n",
    "  time.sleep(10)\n",
    "  \n",
    "  nTries = 20\n",
    "  nTry = 0    \n",
    "\n",
    "  while nTry < nTries:\n",
    "    try:\n",
    "      url = APIEndpoint + Model + \"/analyzeResults/\" + request_id + \"?api-version=2022-08-31\"\n",
    "      payload = \"{}\"\n",
    "      headers = {\n",
    "        'Ocp-Apim-Subscription-Key': APIKey,\n",
    "        'Content-Type': 'application/pdf'\n",
    "      }  \n",
    "\n",
    "      response = requests.request(\"GET\", url, headers=headers, data=payload)\n",
    "      if json.loads(response.text)['status'] == \"succeeded\":\n",
    "        json_data = json.loads(response.text)['analyzeResult']['documents']\n",
    "      \n",
    "        for item in json_data:\n",
    "          df = pd.DataFrame(item['fields'])\n",
    "      \n",
    "        df['style'] = df['style'].replace(to_replace= r'\\n', value= ' ', regex=True)\n",
    "        df.loc[['content'],  ['brewery', 'beer', 'style', 'abv', 'untappd', 'price']]\n",
    "        return df\n",
    "\n",
    "      time.sleep(3)  \n",
    "      nTry += 1\n",
    "    except Exception as e:\n",
    "        return  \"error\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute and Results\n",
    "\n",
    "Skip the first file, subindex[0] since that's always an empty page.  \n",
    "1. Request Inference\n",
    "2. Go back for the result\n",
    "3. Append result in a Dataframe\n",
    "4. Export to Excel File "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ExportResults = pd.DataFrame()\n",
    "\n",
    "for i in range(len(fileList)):\n",
    "    if i != 0:\n",
    "        print(fileList[i])\n",
    "        request_id = Inference(fileList[i])\n",
    "        InferenceResult = GetInference(request_id)\n",
    "        ExportResults = ExportResults.append(InferenceResult)\n",
    "\n",
    "ExportResults.loc[['content'],  ['brewery', 'beer', 'style', 'abv', 'untappd', 'price']].to_excel(r'', header=True) #Destination file for your exported results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0a54084e6b208ee8d1ce3989ffc20924477a5f55f5a43e22e699a6741623861e"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8 (tags/v3.7.8:4b47a5b6ba, Jun 28 2020, 08:53:46) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
